
## 问题
```
在真实的工业界场景中，通常面临标注成本昂贵、泛化迁移能力不足、可解释性不强、计算资源受限、嵌套实体的长尾等问题，

词汇增强、冷启动、泛化性、低资源、噪声、不平衡、领域迁移、可解释、低耗时、否定性

样本少、不均衡、关键词信息融入文本分类（知识库/外部信息融合）


问题分析
	badcase，对应解决
	影响哪些
	上限下限
	相应占比

不同医院、不同疾病、不同科室的文本描述形式不一致，而标注成本又很昂贵，一个通用的NER系统往往不具备“想象中”的泛化迁移能力。当前的NER技术在医疗领域并不适合做成泛化的工具。
由于医疗领域的严肃性，我们既要知其然、更要知其所以然：NER系统往往不能采用“一竿子插到底”的黑箱算法，处理过程应该随着处理对象的层次和深度而逐步叠加模块，下级模块使用上级结果，方便进行迭代优化、并具备可解释性，这样做可解耦医学事件、也便于进行医学实体消歧。
仅仅使用统计模型的NER系统往往不是万能的，医疗领域相关的实体词典和特征挖掘对NER性能也起着关键作用。此外，NER结果往往不能直接使用，还需进行医学术语标准化。
由于医院数据不可出院，需要在院内部署NER系统。而通常医院内部的GPU计算资源又不是很充足（成本问题），我们需要让机器学习模型又轻又快（BERT上不动哇），同时要更充分的利用显存。



todo:
	知识多分发 + 模型分离
	解码限制
	normalization
	单位换算
	图像题目
		三角形和四边形，表格什么的
	特殊类型题目
		公式包裹
		大小题，第三步用到第一步，模型递归人循环
		
```

## 数据
```
数据不足
	模型
	    模型简化
	        整体当做一个预测而不是每个location(tex,nsp当做整体表示）
		独自建模
		    latex 专用embed
		数字都统一到单个拆分
		生成->ner->分类->
	数据
	    精简类别
	    规则化
	    强化特征，重点特征 重复
        数据归一化
            DATE、CURRENCY、EMAIL
	

数据不平衡
	让每个batch都能看到所有类别的样本
	增加权重
	清洗数据，去除噪声，降低负样本数据
	核心点还是难以区分的样本，学习到重点特征

	
```
## 模型

### ICSF
BERT for Joint Intent Classification and Slot Filling
		

### pointer network
对于抽取，复制较多的情况，使用此机制合理  
https://zhuanlan.zhihu.com/p/48959800 

## 数据增强库
```
https://www.youtube.com/watch?v=9O9scQb4sNo 
https://github.com/varinf/TransformersDataAugmentation
NER数据增强
DAGA:https://www.aclweb.org/anthology/2020.emnlp-main.488.pdf
通用数据增强：https://github.com/varinf/TransformersDataAugmentation
分类数据增强：CBERT
https://github.com/1024er/cbert_aug
```

## 多分类
```

https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab
WeightedRandomSampler
https://blog.csdn.net/tyfwin/article/details/108435756


https://blog.csdn.net/xiaohuihui1994/article/details/93049975
https://www.cnblogs.com/wynlfd/p/14101373.html
pytorch 做多分类和多类别
BCEWithLogitsLoss用于单标签二分类或者多标签二分类
CrossEntropyLoss用于多类别分类，输出和目标的维度是(batch,C)，batch是样本数量，C是类别数量，每一个C之间是互斥的，相互关联的，对于每一个batch的C个值，一起求每个C的softmax
```